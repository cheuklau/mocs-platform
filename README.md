# MOCS Platform

## Table of Contents

1. [Introduction](README.md#introduction)
2. [Infrastructure Technologies](README.md#infrastructure-technologies)
3. [Data Engineering Technologies](README.md#data-engineering-technologies)
4. [Use Cases](README.md#use-case)

## Introduction

The goal of the monitored one-click solution (MOCS) platform is to automate the deployment of data engineering pipelines onto Amazon Web Services (AWS). The user supplies basic information of their desired ETL pipeline and the MOCS platform will generate a recommended architecture that meets reliability, scalability and availability starndards while satisfying user budget. If the user agrees, the MOCS platform will automatically provision the proposed architecture onto AWS. In addition, the user will be provided with all the tools needed to make sure the deployment is healthy e.g., centralized logging, monitoring, alerting and access to all web UI endpoints of each service. The MOCS platform should effectively abstract away the complexities of infrastructure-as-code (IaC) from the user.

## Infrastructure Technologies

### Terraform

Terraform will be used to provision AWS networking resources (e.g., virtual private cloud (VPC), security groups, subnets) and the EC2 instances to run Kubernetes using the Amazon Machine Image (AMI) generated by Packer as discussed in the next section. Terraform is also responsible for setting up networking using Flannel and cluster initialization using Kubeadm. An AWS Elastic Load Balancer (ELB) will be placed in front of the cluster to route traffic evenly across all Kubernetes nodes.

### Packer

Packer will be used to create the Amazon Machine Images (AMI) for setting up the Kubernetes cluster. This includes downloading and installing the binaries for Docker, Kubelet, Kubeadm and Kubectl. The Kubernetes master and worker nodes will use the same AMI.

### Docker

Docker will be used to create the container images for each part of the pipeline. The majority of the images are available in `cheuklau` DockerHub.

### Kubernetes

Kubernetes will be used to deploy the data pipeline and all the tools associated with logging, monitoring and alerting.

### Helm

Each of the components in Kubernetes will be packaged as a Helm Chart for quick deployment.

### Traefik

All external and internal traffic will be routed using ingress rules with Traefik acting as the ingress controller. 

### Prometheus and Grafana

Prometheus will be used to monitor metrics (e.g., CPU, memory, storage) on the cluster, application and pod level. Grafana will be used to visualize the metrics in real-time.

### Elastic Stack

The Elastic Stack (Beats, LogStash, ElasticSearch and Kibana) will be used for centralized logging of all applications.

### Alert Manager

Alert Manager will be used to send notifications when metrics and logs are outside normal operating conditions.

## Data Engineering Technologies

### Spark

### Kafka

## Use Cases

### AirAware

The AirAware ETL pipeline is summarized below:
- 500GB of data in S3
- Spark batch-processes data
- Processed data is stored in postgres

The corresponding MOCS input (`airaware.yaml`) is provided below:
```
# Extract stage
extract:
    metadata:
        app: airaware
    storage:
    - type: s3
      location: 
      size: 500 # Default units of GB
transform:
    metadata:
        app: airaware
    stages:
    # Multiple stages can be specified
    - tool: spark
      stopOnCompletion: true # Spin down pods when batch job complete
load:
    metadata:
        app: airaware
    storage:
    - type: postgres
      size: 10 # Estimate of output size after transform
```

To run `airaware.yaml` on MOCS platform:
- To generate the recommended architecture: `mocs --plan airaware.yaml`
- To provision the recommended architecture: `mocs --apply airaware.yaml`